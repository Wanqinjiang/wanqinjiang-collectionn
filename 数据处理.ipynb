{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.interpolate import lagrange\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegressionCV,LinearRegression\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.interpolate import lagrange\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegressionCV,LinearRegression\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import roc_curve\n",
    "import lightgbm as lgb\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(module='sklearn*', action='ignore', category=DeprecationWarning)\n",
    "from catboost import CatBoostClassifier\n",
    "import random\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18618, 35)\n"
     ]
    }
   ],
   "source": [
    "place = 'try1.txt'\n",
    "train = pd.read_csv(place, sep='\\t')\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15342, 35)\n"
     ]
    }
   ],
   "source": [
    "train = train.dropna(axis=0)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.index = list(range(15342))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>性别</th>\n",
       "      <th>fld</th>\n",
       "      <th>年龄</th>\n",
       "      <th>白细胞总数</th>\n",
       "      <th>甘油三酯</th>\n",
       "      <th>谷丙转氨酶</th>\n",
       "      <th>谷草转氨酶</th>\n",
       "      <th>红细胞压积</th>\n",
       "      <th>红细胞总数</th>\n",
       "      <th>肌酐</th>\n",
       "      <th>...</th>\n",
       "      <th>舒张压</th>\n",
       "      <th>体重</th>\n",
       "      <th>体重指数</th>\n",
       "      <th>臀围</th>\n",
       "      <th>血小板压积</th>\n",
       "      <th>腰臀比</th>\n",
       "      <th>腰围</th>\n",
       "      <th>中性粒细胞百分比</th>\n",
       "      <th>age</th>\n",
       "      <th>bmir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>5.96</td>\n",
       "      <td>0.62</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>37.1</td>\n",
       "      <td>4.27</td>\n",
       "      <td>59.5</td>\n",
       "      <td>...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.75</td>\n",
       "      <td>64.0</td>\n",
       "      <td>63.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>6.10</td>\n",
       "      <td>0.79</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>4.28</td>\n",
       "      <td>59.7</td>\n",
       "      <td>...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.69</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>7.67</td>\n",
       "      <td>1.72</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>41.1</td>\n",
       "      <td>5.01</td>\n",
       "      <td>67.4</td>\n",
       "      <td>...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>23.7</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.79</td>\n",
       "      <td>76.0</td>\n",
       "      <td>44.2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>4.80</td>\n",
       "      <td>2.12</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>42.1</td>\n",
       "      <td>4.97</td>\n",
       "      <td>62.2</td>\n",
       "      <td>...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.81</td>\n",
       "      <td>68.0</td>\n",
       "      <td>58.2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10.94</td>\n",
       "      <td>0.72</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>43.6</td>\n",
       "      <td>5.29</td>\n",
       "      <td>61.1</td>\n",
       "      <td>...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>24.8</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.79</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   性别  fld  年龄  白细胞总数  甘油三酯  谷丙转氨酶  谷草转氨酶  红细胞压积  红细胞总数    肌酐  ...   舒张压  \\\n",
       "0   0    0  20   5.96  0.62    8.0   15.0   37.1   4.27  59.5  ...  70.0   \n",
       "1   0    0  20   6.10  0.79   10.0   16.0   39.0   4.28  59.7  ...  70.0   \n",
       "2   0    0  20   7.67  1.72   17.0   16.0   41.1   5.01  67.4  ...  70.0   \n",
       "3   0    0  20   4.80  2.12   10.0   12.0   42.1   4.97  62.2  ...  70.0   \n",
       "4   0    0  20  10.94  0.72   12.0   16.0   43.6   5.29  61.1  ...  80.0   \n",
       "\n",
       "     体重  体重指数    臀围  血小板压积   腰臀比    腰围  中性粒细胞百分比  age  bmir  \n",
       "0  55.0  19.7  85.0   0.23  0.75  64.0      63.5    1     2  \n",
       "1  46.0  19.7  85.0   0.26  0.69  59.0      59.0    1     2  \n",
       "2  60.0  23.7  96.0   0.19  0.79  76.0      44.2    1     2  \n",
       "3  57.0  18.8  84.0   0.18  0.81  68.0      58.2    1     2  \n",
       "4  62.0  24.8  89.0   0.28  0.79  70.0      70.0    1     3  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['性别', 'fld', '年龄', '白细胞总数', '甘油三酯', '谷丙转氨酶', '谷草转氨酶', '红细胞压积', '红细胞总数',\n",
       "       '肌酐', '尿素氮', '尿酸', '平均红细胞体积', '平均红细胞血红蛋白含量', '平均红细胞血红蛋白浓度', '血红蛋白',\n",
       "       '血糖', '血小板数', '总胆固醇', '低密度脂蛋白', '高密度脂蛋白', '红细胞体积分布宽度', '淋巴细胞百分比', '身高',\n",
       "       '收缩压', '舒张压', '体重', '体重指数', '臀围', '血小板压积', '腰臀比', '腰围', '中性粒细胞百分比',\n",
       "       'age', 'bmir'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Tools\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "F:\\Tools\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "fea = train['性别']\n",
    "A1 = fea[fea==1]; B1 = A1.index\n",
    "A2 = fea[fea==0]; B2 = A2.index\n",
    "X1 = train.iloc[B1, :]\n",
    "X2 = train.iloc[B2, :]\n",
    "X1['VAI'] = (X1['腰围']/(39.68+1.88*X1['体重指数'])) * (X1['甘油三酯']/1.03)*(1.31/X1['高密度脂蛋白'])\n",
    "X2['VAI'] = (X2['腰围']/(36.58+1.89*X2['体重指数'])) * (X2['甘油三酯']/0.81)*(1.52/X2['高密度脂蛋白'])\n",
    "train = pd.concat([X1,X2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='性别', data=train, hue='fld')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[\"白红计数比\"] = train[\"白细胞总数\"]/train[\"红细胞总数\"]\n",
    "#train[\"红细胞总体积\"] = train[\"平均红细胞体积\"]*train[\"红细胞总数\"]\n",
    "#train['肾'] = train['肌酐'] + train['尿酸'] + train['尿素氮']\n",
    "#train['总酶'] = train['谷草转氨酶'] + train['谷丙转氨酶']\n",
    "#train['谷草酶ratio'] = train['谷草转氨酶']/np.maximum(train[\"总酶\"].astype(\"float\"),1)\n",
    "#train['谷丙酶ratio'] = train['谷丙转氨酶']/np.maximum(train[\"总酶\"].astype(\"float\"),1)\n",
    "#train['总蛋白'] = train[\"高密度脂蛋白\"] + train[\"低密度脂蛋白\"] + train['血红蛋白']\n",
    "train['谷丙草比']=train['谷丙转氨酶']/train['谷草转氨酶']\n",
    "train['高低蛋白比'] =  train[\"高密度脂蛋白\"]/train[\"低密度脂蛋白\"]\n",
    "#train['谷丙草比lg']=np.log(train['谷丙转氨酶']/train['谷草转氨酶'])\n",
    "train['非高密度脂蛋白'] = train['总胆固醇'] - train['高密度脂蛋白']#这个确实很有用0.002\n",
    "#train['高密度脂蛋白胆固醇ratio'] = train['高密度脂蛋白']/np.maximum(train[\"总胆固醇\"].astype(\"float\"),1) \n",
    "#train['低密度脂蛋白胆固醇ratio'] = train['低密度脂蛋白']/np.maximum(train[\"总胆固醇\"].astype(\"float\"),1)\n",
    "#train['甘三胆固比'] = train['甘油三酯']*train['总胆固醇']#有用0.006\n",
    "#train['低高蛋白比'] = train[\"低密度脂蛋白\"]/train[\"高密度脂蛋白\"]#有用0.004\n",
    "#train['低密度胆固比'] = train[\"低密度脂蛋白\"]/train[\"总胆固醇\"]\n",
    "#train['甘三低蛋白差'] = train[\"低密度脂蛋白\"]-train['甘油三酯']#有用0.004\n",
    "#train['甘三高蛋白比'] = train[\"高密度脂蛋白\"]-train['甘油三酯']\n",
    "#train['非低密度脂蛋白'] = train['总胆固醇'] - train['低密度脂蛋白']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x = train['体重指数'], y = train['fld'])\n",
    "plt.ylabel('fld', fontsize=13)\n",
    "plt.xlabel('体重指数', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15342, 36)\n",
      "13459\n",
      "1883\n"
     ]
    }
   ],
   "source": [
    "y = train['fld']\n",
    "train = train.drop(['fld','bmir','age'],axis=1)\n",
    "print(train.shape)\n",
    "print(np.sum(y==0))\n",
    "print(np.sum(y==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>性别</th>\n",
       "      <th>年龄</th>\n",
       "      <th>白细胞总数</th>\n",
       "      <th>甘油三酯</th>\n",
       "      <th>谷丙转氨酶</th>\n",
       "      <th>谷草转氨酶</th>\n",
       "      <th>红细胞压积</th>\n",
       "      <th>红细胞总数</th>\n",
       "      <th>肌酐</th>\n",
       "      <th>尿素氮</th>\n",
       "      <th>...</th>\n",
       "      <th>体重指数</th>\n",
       "      <th>臀围</th>\n",
       "      <th>血小板压积</th>\n",
       "      <th>腰臀比</th>\n",
       "      <th>腰围</th>\n",
       "      <th>中性粒细胞百分比</th>\n",
       "      <th>VAI</th>\n",
       "      <th>谷丙草比</th>\n",
       "      <th>高低蛋白比</th>\n",
       "      <th>非高密度脂蛋白</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15342.000000</td>\n",
       "      <td>15342.000000</td>\n",
       "      <td>15342.000000</td>\n",
       "      <td>15342.000000</td>\n",
       "      <td>15342.000000</td>\n",
       "      <td>15342.000000</td>\n",
       "      <td>15342.000000</td>\n",
       "      <td>15342.000000</td>\n",
       "      <td>15342.000000</td>\n",
       "      <td>15342.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15342.000000</td>\n",
       "      <td>15342.000000</td>\n",
       "      <td>15342.000000</td>\n",
       "      <td>15342.000000</td>\n",
       "      <td>15342.000000</td>\n",
       "      <td>15342.000000</td>\n",
       "      <td>15342.000000</td>\n",
       "      <td>15342.000000</td>\n",
       "      <td>15342.000000</td>\n",
       "      <td>15342.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.456199</td>\n",
       "      <td>39.933581</td>\n",
       "      <td>6.244497</td>\n",
       "      <td>1.162785</td>\n",
       "      <td>18.179051</td>\n",
       "      <td>18.951309</td>\n",
       "      <td>42.201669</td>\n",
       "      <td>4.780628</td>\n",
       "      <td>61.259085</td>\n",
       "      <td>4.732853</td>\n",
       "      <td>...</td>\n",
       "      <td>22.770278</td>\n",
       "      <td>93.967605</td>\n",
       "      <td>0.234791</td>\n",
       "      <td>0.814347</td>\n",
       "      <td>76.668361</td>\n",
       "      <td>57.334084</td>\n",
       "      <td>1.338338</td>\n",
       "      <td>0.926030</td>\n",
       "      <td>0.612128</td>\n",
       "      <td>3.260037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.498094</td>\n",
       "      <td>13.180147</td>\n",
       "      <td>1.487790</td>\n",
       "      <td>0.816762</td>\n",
       "      <td>17.149062</td>\n",
       "      <td>9.457291</td>\n",
       "      <td>3.903698</td>\n",
       "      <td>0.448523</td>\n",
       "      <td>13.611893</td>\n",
       "      <td>1.237254</td>\n",
       "      <td>...</td>\n",
       "      <td>2.956973</td>\n",
       "      <td>6.393741</td>\n",
       "      <td>0.049773</td>\n",
       "      <td>0.063080</td>\n",
       "      <td>9.288124</td>\n",
       "      <td>7.929071</td>\n",
       "      <td>1.193146</td>\n",
       "      <td>0.327180</td>\n",
       "      <td>0.241804</td>\n",
       "      <td>0.834630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.180000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.600000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>21.940000</td>\n",
       "      <td>0.108932</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.124862</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>4.450000</td>\n",
       "      <td>50.800000</td>\n",
       "      <td>3.857000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.700000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>52.100000</td>\n",
       "      <td>0.720061</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.447296</td>\n",
       "      <td>2.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>42.100000</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>59.582500</td>\n",
       "      <td>4.607500</td>\n",
       "      <td>...</td>\n",
       "      <td>22.600000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>57.400000</td>\n",
       "      <td>1.047950</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.563453</td>\n",
       "      <td>3.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>7.060000</td>\n",
       "      <td>1.380000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>20.900000</td>\n",
       "      <td>45.100000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>70.400000</td>\n",
       "      <td>5.440000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.600000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>62.700000</td>\n",
       "      <td>1.579930</td>\n",
       "      <td>1.076923</td>\n",
       "      <td>0.721953</td>\n",
       "      <td>3.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>20.880000</td>\n",
       "      <td>1189.300000</td>\n",
       "      <td>606.100000</td>\n",
       "      <td>54.800000</td>\n",
       "      <td>7.740000</td>\n",
       "      <td>285.100000</td>\n",
       "      <td>20.580000</td>\n",
       "      <td>...</td>\n",
       "      <td>41.300000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>1.181000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>90.110000</td>\n",
       "      <td>30.167754</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.350877</td>\n",
       "      <td>9.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 性别            年龄         白细胞总数          甘油三酯         谷丙转氨酶  \\\n",
       "count  15342.000000  15342.000000  15342.000000  15342.000000  15342.000000   \n",
       "mean       0.456199     39.933581      6.244497      1.162785     18.179051   \n",
       "std        0.498094     13.180147      1.487790      0.816762     17.149062   \n",
       "min        0.000000     20.000000      2.180000      0.160000      2.500000   \n",
       "25%        0.000000     29.000000      5.200000      0.710000     11.100000   \n",
       "50%        0.000000     37.000000      6.100000      0.970000     15.000000   \n",
       "75%        1.000000     48.000000      7.060000      1.380000     21.000000   \n",
       "max        1.000000     92.000000     23.900000     20.880000   1189.300000   \n",
       "\n",
       "              谷草转氨酶         红细胞压积         红细胞总数            肌酐           尿素氮  \\\n",
       "count  15342.000000  15342.000000  15342.000000  15342.000000  15342.000000   \n",
       "mean      18.951309     42.201669      4.780628     61.259085      4.732853   \n",
       "std        9.457291      3.903698      0.448523     13.611893      1.237254   \n",
       "min        2.000000     23.600000      2.780000      3.000000      1.100000   \n",
       "25%       15.000000     39.500000      4.450000     50.800000      3.857000   \n",
       "50%       17.600000     42.100000      4.750000     59.582500      4.607500   \n",
       "75%       20.900000     45.100000      5.100000     70.400000      5.440000   \n",
       "max      606.100000     54.800000      7.740000    285.100000     20.580000   \n",
       "\n",
       "       ...          体重指数            臀围         血小板压积           腰臀比  \\\n",
       "count  ...  15342.000000  15342.000000  15342.000000  15342.000000   \n",
       "mean   ...     22.770278     93.967605      0.234791      0.814347   \n",
       "std    ...      2.956973      6.393741      0.049773      0.063080   \n",
       "min    ...     14.000000     51.000000      0.030000      0.600000   \n",
       "25%    ...     20.700000     90.000000      0.200000      0.770000   \n",
       "50%    ...     22.600000     94.000000      0.230000      0.810000   \n",
       "75%    ...     24.600000     98.000000      0.260000      0.860000   \n",
       "max    ...     41.300000    140.000000      1.181000      1.200000   \n",
       "\n",
       "                 腰围      中性粒细胞百分比           VAI          谷丙草比         高低蛋白比  \\\n",
       "count  15342.000000  15342.000000  15342.000000  15342.000000  15342.000000   \n",
       "mean      76.668361     57.334084      1.338338      0.926030      0.612128   \n",
       "std        9.288124      7.929071      1.193146      0.327180      0.241804   \n",
       "min       51.000000     21.940000      0.108932      0.151515      0.124862   \n",
       "25%       70.000000     52.100000      0.720061      0.705882      0.447296   \n",
       "50%       76.000000     57.400000      1.047950      0.863636      0.563453   \n",
       "75%       83.000000     62.700000      1.579930      1.076923      0.721953   \n",
       "max      124.000000     90.110000     30.167754      8.000000      4.350877   \n",
       "\n",
       "            非高密度脂蛋白  \n",
       "count  15342.000000  \n",
       "mean       3.260037  \n",
       "std        0.834630  \n",
       "min        0.000000  \n",
       "25%        2.670000  \n",
       "50%        3.170000  \n",
       "75%        3.750000  \n",
       "max        9.970000  \n",
       "\n",
       "[8 rows x 36 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "性别                1.000000\n",
       "年龄               52.000000\n",
       "白细胞总数             3.400000\n",
       "甘油三酯              2.270000\n",
       "谷丙转氨酶          1189.300000\n",
       "谷草转氨酶           606.100000\n",
       "红细胞压积            46.200000\n",
       "红细胞总数             5.080000\n",
       "肌酐               75.430000\n",
       "尿素氮               4.598000\n",
       "尿酸              401.400000\n",
       "平均红细胞体积          90.900000\n",
       "平均红细胞血红蛋白含量      30.100000\n",
       "平均红细胞血红蛋白浓度     331.000000\n",
       "血红蛋白            153.000000\n",
       "血糖                5.430000\n",
       "血小板数            264.000000\n",
       "总胆固醇              4.700000\n",
       "低密度脂蛋白            2.385000\n",
       "高密度脂蛋白            0.890000\n",
       "红细胞体积分布宽度        13.400000\n",
       "淋巴细胞百分比          43.600000\n",
       "身高              174.000000\n",
       "收缩压             110.000000\n",
       "舒张压              70.000000\n",
       "体重               74.000000\n",
       "体重指数             24.400000\n",
       "臀围              100.000000\n",
       "血小板压积             0.290000\n",
       "腰臀比               0.860000\n",
       "腰围               86.000000\n",
       "中性粒细胞百分比         47.600000\n",
       "VAI               3.260905\n",
       "谷丙草比              1.962217\n",
       "高低蛋白比             0.373166\n",
       "非高密度脂蛋白           3.810000\n",
       "Name: 14811, dtype: float64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[6588,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(train)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Tools\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "F:\\Tools\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "F:\\Tools\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "F:\\Tools\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "F:\\Tools\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "F:\\Tools\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "F:\\Tools\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "F:\\Tools\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "F:\\Tools\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "F:\\Tools\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on trainging set is: 0.885528491858118 The accuracy on test set is: 0.8852187246450732\n",
      "The Sensitivity is: 0.228402566700439 The Specificity is 0.9771160039108027\n",
      "auc is: 0.602759285305621\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=10,random_state=0,shuffle=True)\n",
    "clf = LogisticRegression()\n",
    "score1 = []\n",
    "score2 = []\n",
    "Sensitivity = []\n",
    "Specificity = []\n",
    "auc = []\n",
    "for train, test in skf.split(X,y):\n",
    "    X_train,X_test=X[train],X[test]\n",
    "    y_train,y_test=y[train],y[test]\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred1 = clf.predict(X_train)\n",
    "    accuracy1 = np.mean(y_train==y_pred1)\n",
    "    score1.append(accuracy1)\n",
    "    \n",
    "    y_pred2 = clf.predict(X_test)\n",
    "    accuracy2 = np.mean(y_test==y_pred2)\n",
    "    score2.append(accuracy2)\n",
    "    confusion = metrics.confusion_matrix(y_test, y_pred2)\n",
    "    auc_ = metrics.roc_auc_score(y_test, y_pred2)\n",
    "    TP = confusion[1, 1]\n",
    "    TN = confusion[0, 0]\n",
    "    FP = confusion[0, 1]\n",
    "    FN = confusion[1, 0]\n",
    "    TPR = TP/(TP+FN)\n",
    "    TNR = TN/(TN+FP)\n",
    "    Sensitivity.append(TPR)\n",
    "    Specificity.append(TNR)\n",
    "    auc.append(auc_)\n",
    "score1 = np.array(score1)\n",
    "score2 = np.array(score2)\n",
    "Sensitivity = np.array(Sensitivity)\n",
    "Specificity = np.array(Specificity)\n",
    "auc = np.array(auc)\n",
    "print('The accuracy on trainging set is:',np.mean(score1),'The accuracy on test set is:', np.mean(score2))\n",
    "print('The Sensitivity is:', np.mean(Sensitivity), 'The Specificity is', np.mean(Specificity))\n",
    "print('auc is:', np.mean(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Tools\\Anaconda\\lib\\site-packages\\sklearn\\base.py:253: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.20.1 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "pickle_in = open('gbm.pickle','rb')\n",
    "clf = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on trainging set is: 0.7511768655382615 The accuracy on test set is: 0.7340626356010146\n",
      "The Sensitivity is: 0.8427783406506812 The Specificity is 0.7188500693228457\n",
      "auc is: 0.7808142049867632\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=10,random_state=0,shuffle=True)\n",
    "score1 = []\n",
    "score2 = []\n",
    "Sensitivity = []\n",
    "Specificity = []\n",
    "auc = []\n",
    "A = []\n",
    "for train, test in skf.split(X,y):\n",
    "    X_train,X_test=X[train],X[test]\n",
    "    y_train,y_test=y[train],y[test]\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred1 = clf.predict(X_train)\n",
    "    accuracy1 = np.mean(y_train==y_pred1)\n",
    "    score1.append(accuracy1)\n",
    "    \n",
    "    y_pred2 = clf.predict(X_test)\n",
    "    accuracy2 = np.mean(y_test==y_pred2)\n",
    "    score2.append(accuracy2)\n",
    "    confusion = metrics.confusion_matrix(y_test, y_pred2)\n",
    "    auc_ = metrics.roc_auc_score(y_test, y_pred2)\n",
    "    TP = confusion[1, 1]\n",
    "    TN = confusion[0, 0]\n",
    "    FP = confusion[0, 1]\n",
    "    FN = confusion[1, 0]\n",
    "    TPR = TP/(TP+FN)\n",
    "    TNR = TN/(TN+FP)\n",
    "    Sensitivity.append(TPR)\n",
    "    Specificity.append(TNR)\n",
    "    auc.append(auc_)\n",
    "    A.append(clf.booster_.feature_importance())\n",
    "score1 = np.array(score1)\n",
    "score2 = np.array(score2)\n",
    "Sensitivity = np.array(Sensitivity)\n",
    "Specificity = np.array(Specificity)\n",
    "auc = np.array(auc)\n",
    "print('The accuracy on trainging set is:',np.mean(score1),'The accuracy on test set is:', np.mean(score2))\n",
    "print('The Sensitivity is:', np.mean(Sensitivity), 'The Specificity is', np.mean(Specificity))\n",
    "print('auc is:', np.mean(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on trainging set is: 0.7670664662820792 The accuracy on test set is: 0.7488587673177338\n",
      "The Sensitivity is: 0.8220449172576831 The Specificity is 0.7386139849864944\n",
      "auc is: 0.7803294511220888\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=10,random_state=0,shuffle=True)\n",
    "clf = lgb.LGBMClassifier(class_weight={1:8,0:1},categorical_features=[0],\n",
    "                        colsample_bytree=0.8,num_leaves=9,reg_alpha=14,reg_lambda=14,\n",
    "                         min_child_samples=3, importance_type='split')\n",
    "score1 = []\n",
    "score2 = []\n",
    "Sensitivity = []\n",
    "Specificity = []\n",
    "auc = []\n",
    "A = []\n",
    "for train, test in skf.split(X,y):\n",
    "    X_train,X_test=X[train],X[test]\n",
    "    y_train,y_test=y[train],y[test]\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred1 = clf.predict(X_train)\n",
    "    accuracy1 = np.mean(y_train==y_pred1)\n",
    "    score1.append(accuracy1)\n",
    "    \n",
    "    y_pred2 = clf.predict(X_test)\n",
    "    accuracy2 = np.mean(y_test==y_pred2)\n",
    "    score2.append(accuracy2)\n",
    "    confusion = metrics.confusion_matrix(y_test, y_pred2)\n",
    "    auc_ = metrics.roc_auc_score(y_test, y_pred2)\n",
    "    TP = confusion[1, 1]\n",
    "    TN = confusion[0, 0]\n",
    "    FP = confusion[0, 1]\n",
    "    FN = confusion[1, 0]\n",
    "    TPR = TP/(TP+FN)\n",
    "    TNR = TN/(TN+FP)\n",
    "    Sensitivity.append(TPR)\n",
    "    Specificity.append(TNR)\n",
    "    auc.append(auc_)\n",
    "    A.append(clf.booster_.feature_importance())\n",
    "score1 = np.array(score1)\n",
    "score2 = np.array(score2)\n",
    "Sensitivity = np.array(Sensitivity)\n",
    "Specificity = np.array(Specificity)\n",
    "auc = np.array(auc)\n",
    "print('The accuracy on trainging set is:',np.mean(score1),'The accuracy on test set is:', np.mean(score2))\n",
    "print('The Sensitivity is:', np.mean(Sensitivity), 'The Specificity is', np.mean(Specificity))\n",
    "print('auc is:', np.mean(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Tools\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "F:\\Tools\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "F:\\Tools\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "F:\\Tools\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "F:\\Tools\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "F:\\Tools\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "F:\\Tools\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "F:\\Tools\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "F:\\Tools\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "F:\\Tools\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on trainging set is: 0.7665522191614264 The accuracy on test set is: 0.7654150884954235\n",
      "The Sensitivity is: 0.8119694922886411 The Specificity is 0.7588983467467976\n",
      "auc is: 0.7854339195177193\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=10,random_state=0,shuffle=True)\n",
    "clf = LogisticRegression(class_weight={1:7.5,0:1})\n",
    "score1 = []\n",
    "score2 = []\n",
    "Sensitivity = []\n",
    "Specificity = []\n",
    "auc = []\n",
    "for train, test in skf.split(X,y):\n",
    "    X_train,X_test=X[train],X[test]\n",
    "    y_train,y_test=y[train],y[test]\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred1 = clf.predict(X_train)\n",
    "    accuracy1 = np.mean(y_train==y_pred1)\n",
    "    score1.append(accuracy1)\n",
    "    \n",
    "    y_pred2 = clf.predict(X_test)\n",
    "    accuracy2 = np.mean(y_test==y_pred2)\n",
    "    score2.append(accuracy2)\n",
    "    confusion = metrics.confusion_matrix(y_test, y_pred2)\n",
    "    auc_ = metrics.roc_auc_score(y_test, y_pred2)\n",
    "    TP = confusion[1, 1]\n",
    "    TN = confusion[0, 0]\n",
    "    FP = confusion[0, 1]\n",
    "    FN = confusion[1, 0]\n",
    "    TPR = TP/(TP+FN)\n",
    "    TNR = TN/(TN+FP)\n",
    "    Sensitivity.append(TPR)\n",
    "    Specificity.append(TNR)\n",
    "    auc.append(auc_)\n",
    "score1 = np.array(score1)\n",
    "score2 = np.array(score2)\n",
    "Sensitivity = np.array(Sensitivity)\n",
    "Specificity = np.array(Specificity)\n",
    "auc = np.array(auc)\n",
    "print('The accuracy on trainging set is:',np.mean(score1),'The accuracy on test set is:', np.mean(score2))\n",
    "print('The Sensitivity is:', np.mean(Sensitivity), 'The Specificity is', np.mean(Specificity))\n",
    "print('auc is:', np.mean(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
